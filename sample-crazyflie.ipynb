{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae02839",
   "metadata": {},
   "source": [
    "# Sample code for performing obstacle avoidance #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee24e",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc056ed",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CrazyFlie imports:\n",
    "\n",
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce9da5",
   "metadata": {},
   "source": [
    "Set your group number and camera number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb41bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_number = 18\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363ab6b",
   "metadata": {},
   "source": [
    "## Tune the red filtering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758561cb",
   "metadata": {},
   "source": [
    "You can use the following cell to test and visualize the red filtering. This cell *not* make the drone fly. It will connect to the CrazyFlie camera and perform red filtering on the live video feed. You should use this cell to tune the HSV intervals, and then copy/paste your tuned intervals into the __check_contours__ function below. When tuning the intervals, keep in mind that the lighting in the environment can matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107adf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    ''' red bounds:\n",
    "    lb1 = (150, 25, 130)\n",
    "    ub1 = (180, 150, 240)\n",
    "    lb2 = (0, 25, 130)\n",
    "    ub2 = (20, 150, 240)\n",
    "    '''\n",
    "    lb1 = (100, 25, 130)\n",
    "    ub1 = (130, 150, 240)\n",
    "    lb2 = (110, 25, 130)  # Adjust these if a second range is needed\n",
    "    ub2 = (140, 150, 240)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Compute\n",
    "    #cv2.imshow('mask', mask)  \n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5faef",
   "metadata": {},
   "source": [
    "## Helper functions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde9dd",
   "metadata": {},
   "source": [
    "The following cell contains some sample functions which will be useful.\n",
    "\n",
    "In particular, __check_contours__ and __find_greatest_contour__ will perform red filtering on the live camera feed and identify the obstacles. The red filtering is controlled by setting HSV intervals in the __check_contours__ function. Note that the intervals will require tuning and may vary on different drones/cameras.\n",
    "\n",
    "The __adjust_position__ function can also be modified for performing obstacle avoidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45694074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "# FROM LAB 8\n",
    "\n",
    "# returns center of image object\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    center_x = (detection[3] + detection[5]) / 2.0 - 0.5\n",
    "    center_y = (detection[4] + detection[6]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "# retruns image closest to the center of the frame\n",
    "def closest_detection(detections):\n",
    "    \"\"\"TODO: Find the detection closest to the image center\"\"\"\n",
    "    # Loop through and find the detection that is closest to the image center\n",
    "    # You can use the detection_center function above to find the center of the detected object\n",
    "    # Note that the origin (i.e., (x,y) = (0,0)) corresponds to the center of the image. So you can\n",
    "    # use the \"norm\" function above to find the detection that is closest to the center.\n",
    "    # Return the det that corresponds to the closest detection to the image center.\n",
    "    # If nothing is detected, return None.\n",
    "    if not detections:\n",
    "        return None\n",
    "    \n",
    "    minval = float('inf')\n",
    "    detection = detections[0]\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        vec_length = norm(center)\n",
    "        if vec_length < minval:\n",
    "            minval = vec_length\n",
    "            detection = det\n",
    "    return detection\n",
    "\n",
    "\n",
    "# Sort through contours in the image\n",
    "def find_greatest_contour(contours):\n",
    "    largest_area = 0\n",
    "    largest_contour_index = -1\n",
    "    i = 0\n",
    "    total_contours = len(contours)\n",
    "\n",
    "    while i < total_contours:\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_contour_index = i\n",
    "        i += 1\n",
    "\n",
    "    #print(largest_area)\n",
    "\n",
    "    return largest_area, largest_contour_index\n",
    "\n",
    "\n",
    "# Find contours in the image; returns are_there_contours, largest_area, center_x \n",
    "def check_contours(image, lb1, ub1, lb2, ub2):\n",
    "\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    \n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.\n",
    "\n",
    "    largest_area = 0\n",
    "    center_x = 0\n",
    "    \n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    if len(contours) != 0:\n",
    "        \n",
    "        are_there_contours = True\n",
    "        largest_area, largest_contour_index = find_greatest_contour(contours)\n",
    "        largest_contour = contours[largest_contour_index]\n",
    "        moment = cv2.moments(largest_contour)\n",
    "        \n",
    "        if moment[\"m00\"] == 0:\n",
    "            are_there_contours = False\n",
    "        else:\n",
    "            center_x = int(moment[\"m10\"]/moment[\"m00\"])\n",
    "\n",
    "    return True, largest_area, center_x \n",
    "\n",
    "\n",
    "# FROM SAMPLE CODE\n",
    "    \n",
    "# Get the current crazyflie position:\n",
    "def position_estimate(scf):\n",
    "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "    log_config.add_variable('kalman.varPX', 'float')\n",
    "    log_config.add_variable('kalman.varPY', 'float')\n",
    "    log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "    with SyncLogger(scf, log_config) as logger:\n",
    "        for log_entry in logger:\n",
    "            data = log_entry[1]\n",
    "            x = data['kalman.varPX']\n",
    "            y = data['kalman.varPY']\n",
    "            z = data['kalman.varPZ']\n",
    "            \n",
    "    print(x, y, z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "# Set the built-in PID controller:\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    time.sleep(2)\n",
    "    return\n",
    "\n",
    "\n",
    "# Ascend and hover at 1m:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    for y in range(5):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at .85 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.85)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "\n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    print('Descending:')\n",
    "    # Hover at 0.85 meters:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.85)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 25)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint()\n",
    "        time.sleep(0.1)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9e37b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLLER\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "# def adjust_position(cf, current_y):\n",
    "\n",
    "#     print('Adjusting position')\n",
    "\n",
    "#     steps_per_meter = int(10)\n",
    "#     # Set the number here (the iterations of the for-loop) to the number of side steps.\n",
    "#     # You may choose to tune the number and size of the steps.\n",
    "#     for i in range(3): \n",
    "#         current_y = current_y - 1.0/float(steps_per_meter)\n",
    "#         position = [0, current_y, 0.5, 0.0]\n",
    "\n",
    "#         print('Setting position {}'.format(position))\n",
    "#         for i in range(10):\n",
    "#             cf.commander.send_position_setpoint(position[0],\n",
    "#                                                 position[1],\n",
    "#                                                 position[2],\n",
    "#                                                 position[3])\n",
    "#             time.sleep(0.1)\n",
    "\n",
    "#     cf.commander.send_stop_setpoint()\n",
    "#     # Make sure that the last packet leaves before the link is closed.\n",
    "#     # The message queue is not flushed before closing.\n",
    "#     time.sleep(0.1)\n",
    "#     return current_y\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "def adjust_position(cf, image, box_x, box_y, box_width, box_height, current_x, current_y):\n",
    "    x = current_x\n",
    "    y = current_y\n",
    "    delta = 0.02\n",
    "    \n",
    "    _, width, _ = image.shape\n",
    "    margin = .15 * width\n",
    "\n",
    "    r_lb1 = (150, 25, 130)\n",
    "    r_ub1 = (180, 150, 240)\n",
    "    r_lb2 = (0, 25, 130)\n",
    "    r_ub2 = (20, 150, 240)\n",
    "    \n",
    "    red_exists, r_cont_area, r_cont_x = check_contours(image, r_lb1, r_ub1, r_lb2, r_ub2)\n",
    "\n",
    "    # Define lower and upper bounds for blue in HSV\n",
    "    b_lb1 = (100, 25, 130)\n",
    "    b_ub1 = (130, 150, 240)\n",
    "    b_lb2 = (110, 25, 130)  # Adjust these if a second range is needed\n",
    "    b_ub2 = (140, 150, 240)\n",
    "    \n",
    "    # Check for blue contours\n",
    "    blue_exists, b_cont_area, b_cont_x = check_contours(image, b_lb1, b_ub1, b_lb2, b_ub2)\n",
    "    \n",
    "    #if box_x == None:   \n",
    "        #blue_exists = False\n",
    "    \n",
    "    # CASE 1: Obstacle(s) are visible and close --> move away L/R, pref center\n",
    "    if red_exists and r_cont_area > 4000:\n",
    "        print(\"Avoiding obstacle...\")        \n",
    "        print(\"r_cont_x:\", r_cont_x)\n",
    "        \n",
    "        if r_cont_x > width/2 - margin and r_cont_x < width/2 + margin:\n",
    "            # preference towards middle\n",
    "            \n",
    "            if r_cont_x > width/2:\n",
    "                y = y + delta\n",
    "                print(\"moving left\")\n",
    "            else:\n",
    "                y = y - delta\n",
    "                print(\"moving right\")\n",
    "    \n",
    "\n",
    "   # CASE 2: Final goal in sight --> center image\n",
    "    elif blue_exists and b_cont_area:\n",
    "        print(\"Seeing Bird:\")\n",
    "        #print(\"w:\", box_width, \"h:\", box_height)\n",
    "        if box_width>= 0.25 or box_height>= 0.175:\n",
    "            print(\"Landing...\")\n",
    "            return True, x, y\n",
    "      \n",
    "        err = 0.075\n",
    "        delta = 0.02\n",
    "        \n",
    "        if box_x > err:\n",
    "            y = y - delta\n",
    "            print(\"moving right\")\n",
    "        elif box_x < -1 * err:\n",
    "            y = y + delta\n",
    "            print(\"moving left\")\n",
    "\n",
    "   # CASE 3: else go forward??.\n",
    "    else: \n",
    "        x = x + delta\n",
    "        print(\"moving forward\")\n",
    "     \n",
    "    y_command = y\n",
    "    x_command = x\n",
    "\n",
    "    # set new position, hover at 0.85 meters\n",
    "    cf.commander.send_position_setpoint(x_command, y_command, 0.85, 0) # Do not edit this line\n",
    "    return False, x_command, y_command\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fbec4",
   "metadata": {},
   "source": [
    "## Test obstacle avoidance on the CrazyFlie ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd18e2",
   "metadata": {},
   "source": [
    "The following cell *will* fly the drone. Place the CrazyFlie in front of an obstacle in the netted area for testing. This cell will perform object detection and avoidance using the red filtering defined in the helper functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca756a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning interfaces for Crazyflies...\n",
      "Crazyflies found:\n",
      "radio://0/18/2M\n",
      "radio://0/101/2M\n",
      "radio://0/105/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/105/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/105/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "Capturing.....\n",
      "Initializing PID Controller\n",
      "Capturing.....\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "adjust_position() missing 6 required positional arguments: 'box_x', 'box_y', 'box_width', 'box_height', 'current_x', and 'current_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m(check_contours(frame)):\n\u001b[1;32m---> 55\u001b[0m                 current_y \u001b[38;5;241m=\u001b[39m \u001b[43madjust_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(elapsed \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10.0\u001b[39m):\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: adjust_position() missing 6 required positional arguments: 'box_x', 'box_y', 'box_width', 'box_height', 'current_x', and 'current_y'"
     ]
    }
   ],
   "source": [
    "# Set the URI the Crazyflie will connect to\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "# Check that CrazyFlie devices are available:\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascent to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "        current_y = 0.0\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        \n",
    "\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "\n",
    "            elapsed = time.time() - t\n",
    "            if(elapsed > 5.0):\n",
    "\n",
    "                print('Capturing.....')\n",
    "\n",
    "                if ret:\n",
    "                    #cv2.imshow('frame',frame)\n",
    "\n",
    "                    if(ascended_bool==0):\n",
    "                        set_PID_controller(cf)\n",
    "                        ascend_and_hover(cf)\n",
    "                        ascended_bool = 1\n",
    "                    else:\n",
    "\n",
    "                        if(check_contours(frame)):\n",
    "                            current_y = adjust_position(cf, current_y)\n",
    "\n",
    "            if(elapsed > 10.0):\n",
    "                        break\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3b70281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "    \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "                        framework='TensorFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cbff18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning interfaces for Crazyflies...\n",
      "Crazyflies found:\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/20/2M\n",
      "radio://0/101/2M\n",
      "radio://0/18/2M\n",
      "radio://0/101/2M\n",
      "Initializing PID Controller\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 375\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 381\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 385\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 388\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 377\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 404\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 403\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 417\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 424\n",
      "Avoiding obstacle...\n",
      "cont_x: 421\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 294\n",
      "moving right\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 311\n",
      "moving right\n",
      "Avoiding obstacle...\n",
      "cont_x: 297\n",
      "moving right\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 312\n",
      "moving right\n",
      "Avoiding obstacle...\n",
      "cont_x: 313\n",
      "moving right\n",
      "Avoiding obstacle...\n",
      "cont_x: 312\n",
      "moving right\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 600\n",
      "Avoiding obstacle...\n",
      "cont_x: 261\n",
      "moving right\n",
      "Avoiding obstacle...\n",
      "cont_x: 262\n",
      "moving right\n",
      "Avoiding obstacle...\n",
      "cont_x: 257\n",
      "moving right\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 209\n",
      "Avoiding obstacle...\n",
      "cont_x: 451\n",
      "Avoiding obstacle...\n",
      "cont_x: 451\n",
      "Avoiding obstacle...\n",
      "cont_x: 217\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 460\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 452\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 470\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 560\n",
      "Avoiding obstacle...\n",
      "cont_x: 332\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 333\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 345\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 347\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 351\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 356\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 474\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 368\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 400\n",
      "moving left\n",
      "Avoiding obstacle...\n",
      "cont_x: 400\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 401\n",
      "moving left\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Avoiding obstacle...\n",
      "cont_x: 445\n",
      "Avoiding obstacle...\n",
      "cont_x: 450\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "moving forward\n",
      "Seeing Bird:\n",
      "w: 0.9938857 h: 0.79566056\n",
      "Landing...\n",
      "Descending:\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "\n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "                        framework='TensorFlow')\n",
    "\n",
    "# ************ Parameters that might be useful to change ************ \n",
    "# COCO label id that we want to track\n",
    "tracking_label = 2  #BIRD = 16, BICYCLE = 2\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "group_number = 18\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 1\n",
    "\n",
    "# Confidence of detection (of the bird image)\n",
    "confidence = 0.4\n",
    "\n",
    "# ******************************************************************\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascend to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "\n",
    "        # capture the video\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        ret, prev_frame = cap.read()\n",
    "        \n",
    "        # get the video frames' width and height\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "        # flag indicating whether to exit the main loop and then descend\n",
    "        exit_loop = False\n",
    "\n",
    "        # Ascend and hover a bit\n",
    "        set_PID_controller(cf)\n",
    "        ascend_and_hover(cf)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        x_cur = 0\n",
    "        y_cur = 0\n",
    "        \n",
    "        # detect objects in each frame of the video\n",
    "        while cap.isOpened() and not exit_loop:\n",
    "            \n",
    "            # Try to read image\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                # image = (frame + prev_frame)/2\n",
    "                # prev_frame = frame\n",
    "                image = frame\n",
    "                image_height, image_width, _ = image.shape\n",
    "                \n",
    "                # create blob from image\n",
    "                blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), \n",
    "                                        swapRB=True)\n",
    "\n",
    "                # forward propagate image\n",
    "                model.setInput(blob)\n",
    "                detections = model.forward()\n",
    "\n",
    "                # select detections that match selected class label\n",
    "                matching_detections = [d for d in detections[0, 0] if d[1] == tracking_label]\n",
    "\n",
    "                # select confident detections\n",
    "                confident_detections = [d for d in matching_detections if d[2] > confidence]\n",
    "\n",
    "                # get detection closest to center of field of view and draw it\n",
    "                det = closest_detection(confident_detections) # This relies on the function you wrote above\n",
    "\n",
    "\n",
    "                if det is not None:\n",
    "                # get the class id\n",
    "                    class_id = det[1]\n",
    "                    # map the class id to the class \n",
    "                    class_name = class_names[int(class_id)-1]\n",
    "                    color = COLORS[int(class_id)]\n",
    "                    # get the bounding box coordinates\n",
    "                    box_x = det[3] * image_width\n",
    "                    box_y = det[4] * image_height\n",
    "                    # get the bounding box width and height\n",
    "                    box_width = det[5] * image_width\n",
    "                    box_height = det[6] * image_height\n",
    "                    # draw a rectangle around each detected object\n",
    "                    cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=2)\n",
    "                    # put the class name text on the detected object\n",
    "                    cv2.putText(image, class_name, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "                    _, _, _, box_x, box_y, box_width, box_height = det\n",
    "                    box_x, box_y = detection_center(det)\n",
    "                    \n",
    "                else:\n",
    "                    box_x = None\n",
    "                    box_y = None\n",
    "                    box_width = None\n",
    "                    box_height = None\n",
    "\n",
    "                exit_loop, x_cur, y_cur = adjust_position(cf, image, box_x, box_y, box_width, box_height, x_cur, y_cur)\n",
    "\n",
    "                # Check image\n",
    "                cv2.imshow('image', image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                print('no image!!')\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "        \n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77978172-d5c2-4850-a2cb-b36106ca87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02757a03-9540-4571-a382-bc9d7bb9fc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0108022-2851-45d9-89c8-9627644d5aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
