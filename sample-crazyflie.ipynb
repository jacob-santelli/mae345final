{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae02839",
   "metadata": {},
   "source": [
    "# Sample code for performing obstacle avoidance #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee24e",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc056ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CrazyFlie imports:\n",
    "\n",
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce9da5",
   "metadata": {},
   "source": [
    "Set your group number and camera number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb41bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_number = 18\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363ab6b",
   "metadata": {},
   "source": [
    "## Tune the red filtering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758561cb",
   "metadata": {},
   "source": [
    "You can use the following cell to test and visualize the red filtering. This cell *not* make the drone fly. It will connect to the CrazyFlie camera and perform red filtering on the live video feed. You should use this cell to tune the HSV intervals, and then copy/paste your tuned intervals into the __check_contours__ function below. When tuning the intervals, keep in mind that the lighting in the environment can matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107adf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2799.162] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (150, 25, 130)\n",
    "    ub1 = (180, 150, 240)\n",
    "    lb2 = (0, 25, 130)\n",
    "    ub2 = (20, 150, 240)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Compute\n",
    "    cv2.imshow('mask', mask)    \n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5faef",
   "metadata": {},
   "source": [
    "## Helper functions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde9dd",
   "metadata": {},
   "source": [
    "The following cell contains some sample functions which will be useful.\n",
    "\n",
    "In particular, __check_contours__ and __findGreatesContour__ will perform red filtering on the live camera feed and identify the obstacles. The red filtering is controlled by setting HSV intervals in the __check_contours__ function. Note that the intervals will require tuning and may vary on different drones/cameras.\n",
    "\n",
    "The __adjust_position__ function can also be modified for performing obstacle avoidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45694074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current crazyflie position:\n",
    "def position_estimate(scf):\n",
    "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "    log_config.add_variable('kalman.varPX', 'float')\n",
    "    log_config.add_variable('kalman.varPY', 'float')\n",
    "    log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "    with SyncLogger(scf, log_config) as logger:\n",
    "        for log_entry in logger:\n",
    "            data = log_entry[1]\n",
    "            x = data['kalman.varPX']\n",
    "            y = data['kalman.varPY']\n",
    "            z = data['kalman.varPZ']\n",
    "            \n",
    "    print(x, y, z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "# Set the built-in PID controller:\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    time.sleep(2)\n",
    "    return\n",
    "\n",
    "\n",
    "# Ascend and hover at 1m:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    for y in range(5):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "\n",
    "# Sort through contours in the image\n",
    "def findGreatesContour(contours):\n",
    "    largest_area = 0\n",
    "    largest_contour_index = -1\n",
    "    i = 0\n",
    "    total_contours = len(contours)\n",
    "\n",
    "    while i < total_contours:\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_contour_index = i\n",
    "        i += 1\n",
    "\n",
    "    #print(largest_area)\n",
    "\n",
    "    return largest_area, largest_contour_index\n",
    "\n",
    "\n",
    "# Find contours in the image\n",
    "def check_contours(frame):\n",
    "\n",
    "    print('Checking image:')\n",
    "\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (150, 25, 130)\n",
    "    ub1 = (180, 150, 240)\n",
    "    lb2 = (0, 25, 130)\n",
    "    ub2 = (20, 150, 240)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_area, largest_contour_index = findGreatesContour(contours)\n",
    "\n",
    "    print(largest_area)\n",
    "\n",
    "    if largest_area > 100:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "def adjust_position(cf, current_y):\n",
    "\n",
    "    print('Adjusting position')\n",
    "\n",
    "    steps_per_meter = int(10)\n",
    "    # Set the number here (the iterations of the for-loop) to the number of side steps.\n",
    "    # You may choose to tune the number and size of the steps.\n",
    "    for i in range(3): \n",
    "        current_y = current_y - 1.0/float(steps_per_meter)\n",
    "        position = [0, current_y, 0.5, 0.0]\n",
    "\n",
    "        print('Setting position {}'.format(position))\n",
    "        for i in range(10):\n",
    "            cf.commander.send_position_setpoint(position[0],\n",
    "                                                position[1],\n",
    "                                                position[2],\n",
    "                                                position[3])\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    cf.commander.send_stop_setpoint()\n",
    "    # Make sure that the last packet leaves before the link is closed.\n",
    "    # The message queue is not flushed before closing.\n",
    "    time.sleep(0.1)\n",
    "    return current_y\n",
    "\n",
    "\n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    print('Descending:')\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 25)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint()\n",
    "        time.sleep(0.1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fbec4",
   "metadata": {},
   "source": [
    "## Test obstacle avoidance on the CrazyFlie ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd18e2",
   "metadata": {},
   "source": [
    "The following cell *will* fly the drone. Place the CrazyFlie in front of an obstacle in the netted area for testing. This cell will perform object detection and avoidance using the red filtering defined in the helper functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca756a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URI the Crazyflie will connect to\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "# Check that CrazyFlie devices are available:\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascent to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "        current_y = 0.0\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        \n",
    "\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "\n",
    "            elapsed = time.time() - t\n",
    "            if(elapsed > 5.0):\n",
    "\n",
    "                print('Capturing.....')\n",
    "\n",
    "                if ret:\n",
    "                    #cv2.imshow('frame',frame)\n",
    "\n",
    "                    if(ascended_bool==0):\n",
    "                        set_PID_controller(cf)\n",
    "                        ascend_and_hover(cf)\n",
    "                        ascended_bool = 1\n",
    "                    else:\n",
    "\n",
    "                        if(check_contours(frame)):\n",
    "                            current_y = adjust_position(cf, current_y)\n",
    "\n",
    "            if(elapsed > 10.0):\n",
    "                        break\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b70281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "    \n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "                        framework='TensorFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur):\n",
    "   \"\"\"\n",
    "   cf: crazyflie instance\n",
    "   box_x: x coordinate of the center of the bounding box in the image\n",
    "   box_y: y coordinate of the center of the bounding box in the image\n",
    "   box_width: width of the bounding box in the image\n",
    "   box_height: height of the bounding box in the image\n",
    "   x_cur: current x position\n",
    "   y_cur: current y position\n",
    "   \n",
    "   Return True to indicate that the drone is close to the target and thus exit the loop to stop and descend, new x, new y\n",
    "   Return False to indicate continuing to follow the target, new x, new y.\n",
    "   \n",
    "   \"\"\"\n",
    "   \n",
    "   #### TO DO: Fill below ####\n",
    "   # Exit condition/method using size of the bounding box\n",
    "   if box_width>= 0.9 or box_height>= 0.95:\n",
    "      print(\"END!\")\n",
    "      return True, x_cur, y_cur\n",
    "   \n",
    "   #### TO DO: Fill below ####\n",
    "   # Determine the x and y velocity\n",
    "   y = y_cur\n",
    "   x = x_cur\n",
    "\n",
    "   err = 0.075\n",
    "\n",
    "   delta = 0.02\n",
    "   print(\"\\n\\nbox_x\", box_x, \"\\nbox_y\", box_y)\n",
    "   \n",
    "   if box_x > err:\n",
    "      y = y - delta\n",
    "   elif box_x < -1 * err:\n",
    "      y = y + delta\n",
    "   else:\n",
    "      x = x + delta\n",
    "      \n",
    "   y_command = y\n",
    "   x_command = x\n",
    "   \n",
    "   # Set velocity\n",
    "   cf.commander.send_position_setpoint(x_command, y_command, 1, 0) # Do not edit this line\n",
    "\n",
    "   return False, x_command, y_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "\n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "                        framework='TensorFlow')\n",
    "\n",
    "# ************ Parameters that might be useful to change ************ \n",
    "# COCO label id that we want to track\n",
    "tracking_label = 16 # BIRD = 16\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "group_number = 18\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0\n",
    "\n",
    "# Confidence of detection (of the bird image)\n",
    "confidence = 0.4\n",
    "\n",
    "# ******************************************************************\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascend to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "\n",
    "        # capture the video\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        ret, prev_frame = cap.read()\n",
    "        \n",
    "        # get the video frames' width and height\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "        # flag indicating whether to exit the main loop and then descend\n",
    "        exit_loop = False\n",
    "\n",
    "        # Ascend and hover a bit\n",
    "        set_PID_controller(cf)\n",
    "        ascend_and_hover(cf)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        x_cur = 0\n",
    "        y_cur = 0\n",
    "        \n",
    "        # detect objects in each frame of the video\n",
    "        while cap.isOpened() and not exit_loop:\n",
    "            \n",
    "            # Try to read image\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                image = frame\n",
    "                image_height, image_width, _ = image.shape\n",
    "\n",
    "                # create blob from image\n",
    "                blob = cv2.dnn.blobFromImage(image=image, size=(300, 300), mean=(104, 117, 123), \n",
    "                                             swapRB=True)\n",
    "\n",
    "                # forward propagate image\n",
    "                model.setInput(blob)\n",
    "                detections = model.forward()\n",
    "\n",
    "                # select detections that match selected class label\n",
    "                matching_detections = [d for d in detections[0, 0] if d[1] == tracking_label]\n",
    "\n",
    "                # select confident detections\n",
    "                confident_detections = [d for d in matching_detections if d[2] > confidence]\n",
    "\n",
    "                # get detection closest to center of field of view and draw it\n",
    "                det = closest_detection(confident_detections) # This relies on the function you wrote above\n",
    "                \n",
    "                if det is not None:\n",
    "                    # get the class id\n",
    "                    class_id = det[1]\n",
    "                    # map the class id to the class \n",
    "                    class_name = class_names[int(class_id)-1]\n",
    "                    color = COLORS[int(class_id)]\n",
    "                    # get the bounding box coordinates\n",
    "                    box_x = det[3] * image_width\n",
    "                    box_y = det[4] * image_height\n",
    "                    # get the bounding box width and height\n",
    "                    box_width = det[5] * image_width\n",
    "                    box_height = det[6] * image_height\n",
    "                    # draw a rectangle around each detected object\n",
    "                    cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=2)\n",
    "                    # put the class name text on the detected object\n",
    "                    cv2.putText(image, class_name, (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "                # If nothing is detected, hover\n",
    "                if det is None:\n",
    "                    print('no detection...hovering')\n",
    "                    hover(cf)\n",
    "\n",
    "                # otherwise  move towards target\n",
    "                else:\n",
    "                    print('detection...tracking')\n",
    "                    _, _, _, box_x, box_y, box_width, box_height = det\n",
    "                    box_x, box_y = detection_center(det)\n",
    "                    exit_loop, x_cur, y_cur = controller(cf, box_x, box_y, box_width, box_height, x_cur, y_cur)\n",
    "\n",
    "                # Check image\n",
    "                cv2.imshow('image', image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                print('no image!!')\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "        \n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae345",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
